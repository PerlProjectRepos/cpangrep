#!/usr/bin/env perl
use strict;
use 5.010;
use FindBin;
use lib "$FindBin::RealBin/../lib";

use AnyEvent::Redis;
use Config::GitLike;
use EV;
use File::Basename qw(basename);
use IO::AIO qw(mmap aio_readahead);
use JSON;
use POSIX ();
use Time::HiRes qw(time);
use re::engine::RE2;

use WWW::CPANGrep::Slab::Common;

my $config = Config::GitLike->new(confname => "cpangrep")->load_file("etc/config");
my $dir = $config->{"location.slabs"};

my $c = $ARGV[0] || $config->{"matcher.concurrency"} || 8;

# XXX: Use some module for this, this is silly
if($c > 1) {
  for(1 .. $c) {
    my $pid = fork;
    if($pid) {
      if($_ == $c) { exit }
      next;
    } else {
      last;
    }
  }
}

my $redis = AnyEvent::Redis->new;

sub open_cached {
  my($file) = @_;
  state(%cache, %cache_size);

  if($config->{"location.huge"}) {
    my $huge = $config->{"location.huge"} . "/" . basename($file);
    open my $orig_fh, "<", $file or die $!;
    eval {
      if(!-f $huge) {
        print "Create $huge\n";
        # racy, but everyone wins.
        open my $fh, "+>", $huge or die $!;
        mmap my $pm, -s $orig_fh, IO::AIO::PROT_READ|IO::AIO::PROT_WRITE,
          IO::AIO::MAP_SHARED, $fh or die $!;
        local $/;
        substr($pm, 0, -s $orig_fh, <$orig_fh>);
        close $fh or die $!;
      }
      die "Huge file not large enough" if -s $huge < -s $orig_fh;
      $file = $huge;
      $cache_size{$file} = -s $orig_fh;
    } or do {
      print "Failed to use hugetlbfs for $huge: $@\n";
      $cache_size{$file} = -s $file;
    };
  } else {
    $cache_size{$file} = -s $file;
  }

  open $cache{$file}, "<", $file or die "$file: $!" unless $cache{$file};
  mmap my $pm, $cache_size{$file}, IO::AIO::PROT_READ, IO::AIO::MAP_SHARED, $cache{$file} or die $!;
  IO::AIO::madvise $pm, 0, $cache_size{$file},
    IO::AIO::MADV_WILLNEED | IO::AIO::MADV_SEQUENTIAL;
  return $pm;
}

sub do_match {
  my($re, $max, $channel, $process) = @_;

  my $matches = 0;

  $re = qr/$re/m;

  my $i = 0;
  my $pm_next = open_cached($dir . "/" . $process->[$i++]);

  for my $file(@$process) {
    my $pm = $pm_next;

    if(my $next = $process->[$i++]) {
      $pm_next = open_cached($dir . "/" . $next);
    }

    my @results;
    while($pm =~ /$re/gm) {
      if($+[0] - $-[0] > 1e5) {
	 $redis->publish($channel => encode_json {
	     error => "Regexp is too greedy"
         });
         return;
      }

      # XXX: A bit broken in edge cases.
      # Be careful not to use regexps!
      my $previous = rindex($pm, "\n", $-[0]);
      $previous = 1+rindex($pm, "\n", $previous-1) if $previous > 0;
      my $next = index($pm, "\n", $+[0]);
      $next = index($pm, "\n", 1+$next) if $next > 0;

      # Limit length of snippet, 200 bytes should be enough for anyone
      if($next > $previous + 200) {
	$previous = $previous < $-[0] - 100 ? $-[0] - 100 : $previous;
	$next = $next > $+[0] + 100 ? $+[0] + 100 : $next;
      }

      my $match = [$-[0], $+[0]];

      # Calculate matching line numbers which, unlike the returned snippet and
      # match range, are adjusted for the _indexed_ file contained within the
      # slab file.  Adjustment happens here rather than in WWW::CPANGrep::search()
      # because it lacks easy and fast access to the slab or indexed file
      # content for line counting.
      my $indexed_file_offset = rindex($pm, SLAB_SEPERATOR, $match->[0]);
      if ($indexed_file_offset >= 0) {
          $indexed_file_offset += length SLAB_SEPERATOR;
      } else {
          $indexed_file_offset = 0;
      }

      my $text  = substr($pm, $previous, $next - $previous);
      my $start = 1 + substr($pm, $indexed_file_offset, $match->[0] - $indexed_file_offset) =~ tr/\n//;
      my $end   = $start + (substr($pm, $match->[0], $match->[1] - $match->[0]) =~ tr/\n//);

      push @results, {
	zset    => $file,
	text    => $text,
	snippet => [$previous, $next],
	match   => $match,
	line    => [$start, $end],
      };
      
      last if ++$matches > $max;
    }

    $redis->publish($channel => encode_json \@results);

    return if $matches > $max;
  }
}

print "$$: ready\n";

my $HUP_set = POSIX::SigSet->new(POSIX::SIGHUP);
$SIG{HUP} = sub {
  # (Arguably due to a bug in perl's signal handling) we end up with the
  # signal still blocked after the exec(), so unblock it manually now.
  POSIX::sigprocmask(POSIX::SIG_UNBLOCK, $HUP_set);
  exec $^X, $0, 1;
  die "exec() failed: $!";
};

while(1) {
  while(my $item = $redis->blpop("queue:cpangrep:slabsearch", 60)->recv) {
    last unless $item->[0];
    POSIX::sigprocmask(POSIX::SIG_BLOCK, $HUP_set);
    print "$$: processing job: $item->[1]\n";
    my $job = decode_json $item->[1];
    my $slabs = [map $redis->lindex($job->{slablist}, $_)->recv, @{$job->{slabs}}];
    my $max = $job->{max} || 500;
    my $start = time;
    do_match($job->{re}, $max, $job->{notify}, $slabs);
    $redis->publish($job->{notify} => encode_json {
	done => 1,
	id => $job->{id}});
    my $end = time;
    print "$$: job done (", $end-$start, "s)\n";
    POSIX::sigprocmask(POSIX::SIG_UNBLOCK, $HUP_set);
  }
  $redis->ping->recv;
}
